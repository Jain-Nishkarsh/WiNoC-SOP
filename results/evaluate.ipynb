{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f031933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b34676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_noxim_output(output):\n",
    "    \"\"\"\n",
    "    Parse the Noxim simulation output and extract relevant metrics.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    buffer_data = []\n",
    "    lines = output.splitlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Total received packets\" in line:\n",
    "            metrics[\"total_received_packets\"] = int(line.split(\":\")[-1].strip())\n",
    "        elif \"Total received flits\" in line:\n",
    "            metrics[\"total_received_flits\"] = int(line.split(\":\")[-1].strip())\n",
    "        elif \"Received/Ideal flits Ratio\" in line:\n",
    "            metrics[\"received_ideal_flits_ratio\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Average wireless utilization\" in line:\n",
    "            metrics[\"average_wireless_utilization\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Global average delay (cycles)\" in line:\n",
    "            metrics[\"global_average_delay\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Max delay (cycles)\" in line:\n",
    "            metrics[\"max_delay\"] = int(line.split(\":\")[-1].strip())\n",
    "        elif \"Network throughput (flits/cycle)\" in line:\n",
    "            metrics[\"network_throughput\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Average IP throughput (flits/cycle/IP)\" in line:\n",
    "            metrics[\"average_ip_throughput\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Total energy (J)\" in line:\n",
    "            metrics[\"total_energy\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Dynamic energy (J)\" in line:\n",
    "            metrics[\"dynamic_energy\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif \"Static energy (J)\" in line:\n",
    "            metrics[\"static_energy\"] = float(line.split(\":\")[-1].strip())\n",
    "        elif line.startswith(\"Router id\"):\n",
    "            # Start of buffer data\n",
    "            buffer_start_index = lines.index(line) + 2\n",
    "            for buffer_line in lines[buffer_start_index:]:\n",
    "                if buffer_line.strip() == \"\":\n",
    "                    break\n",
    "                # Parse the tab-separated values into a structured dictionary\n",
    "                buffer_values = buffer_line.split(\"\\t\")\n",
    "                router_data = {\n",
    "                    \"router_id\": int(buffer_values[0]),\n",
    "                    \"buffer_n_mean\": float(buffer_values[1]) if buffer_values[1] else None,\n",
    "                    \"buffer_n_max\": int(buffer_values[2]) if buffer_values[2] else None,\n",
    "                    \"buffer_e_mean\": float(buffer_values[3]) if buffer_values[3] else None,\n",
    "                    \"buffer_e_max\": int(buffer_values[4]) if buffer_values[4] else None,\n",
    "                    \"buffer_s_mean\": float(buffer_values[5]) if buffer_values[5] else None,\n",
    "                    \"buffer_s_max\": int(buffer_values[6]) if buffer_values[6] else None,\n",
    "                    \"buffer_w_mean\": float(buffer_values[7]) if buffer_values[7] else None,\n",
    "                    \"buffer_w_max\": int(buffer_values[8]) if buffer_values[8] else None,\n",
    "                    \"buffer_l_mean\": float(buffer_values[9]) if buffer_values[9] else None,\n",
    "                    \"buffer_l_max\": int(buffer_values[10]) if buffer_values[10] else None,\n",
    "                }\n",
    "                buffer_data.append(router_data)\n",
    "    \n",
    "    metrics[\"buffer_data\"] = buffer_data\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb6111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_to_pickle(data, filename):\n",
    "    \"\"\"\n",
    "    Save the parsed data to a pickle file.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bfe0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation with PIR=0.0001\n",
      "Running simulation with PIR=0.0006\n",
      "Running simulation with PIR=0.0011\n",
      "Running simulation with PIR=0.0016\n",
      "Running simulation with PIR=0.0021\n",
      "Running simulation with PIR=0.0026\n",
      "Running simulation with PIR=0.0031\n",
      "Running simulation with PIR=0.0036\n",
      "Data saved to ./64_16h_4channels/64_16h_4channels_results_20250906_165646.pkl\n"
     ]
    }
   ],
   "source": [
    "FILENAME = \"64_16h_4channels\"\n",
    "\n",
    "# Create a dictionary to store results for all PIRs\n",
    "all_results = {}\n",
    "\n",
    "# Generate a timestamp for the run\n",
    "run_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_pickle_file = f\"./{FILENAME}/{FILENAME}_results_{run_timestamp}.pkl\"\n",
    "\n",
    "for j in range(8):\n",
    "    i = round(0.0001 + (0.0005 * j), 4)\n",
    "    print(f\"Running simulation with PIR={i}\")\n",
    "\n",
    "    result = subprocess.run(['./noxim', '-config', f'../custom_config/{FILENAME}.yaml', '-pir', str(i), 'poisson'],\n",
    "                            capture_output=True, text=True, cwd='../bin')\n",
    "\n",
    "    output = result.stdout\n",
    "    metrics = parse_noxim_output(output)\n",
    "    all_results[i] = metrics\n",
    "\n",
    "# Save all results to a single pickle file\n",
    "save_to_pickle(all_results, output_pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
